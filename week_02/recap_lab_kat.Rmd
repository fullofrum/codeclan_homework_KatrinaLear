---
title: "Recap Lab"
output:
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    df_print: paged
    css: ../../../styles.css
  pdf_document: default
---


```{r}
library(tidyverse)
diet_comp <- read_csv("data/dietary-composition-by-country.csv")
library(janitor)
library(stringr)

clean_diet <- clean_names(diet_comp)
```


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = F)
```

<br>

Use this lab to recap (almost) everything you've learnt so far on the course.
 
The data for this lab comes from Our World in Data and contains the average daily per capita supply of calories from a range of food commodities by country across many years. You can read more about the data [here](https://ourworldindata.org/grapher/dietary-composition-by-country) in the 'Sources' tab.

<br>

**Question 1**

Read in the data containing dietary compositions and familiarise yourself with it.

<br>

**Question 2**

Change the data to long format with food categories going to a column called `kcal_source` and the calorie values going to a column called `avg_daily_kcals`. Save into variable `diet_comp_clean`

data : the data you want to pivot
cols : the columns you want to pivot
names_to : the name of your new column where your old column names (the ones you are pivoting) will go.
values_to : the name of your new column where your data will go (that was in your old columns)

```{r}
diet_comp_clean <- clean_diet %>% 
pivot_longer(cols = (alcoholic_beverages_fao_2017:wheat_fao_2017),  # gives range of columns I want to pivot
             names_to = "kcal_source",  # name of the new column for columns names
             values_to = "avg_daily_kcals") # name of the new column for the values
```




**Question 3**

Clean `kcal_source` categories by removing any unnecessary information. Then clean all column names, and rename the column 'entity' to 'country'. Overwrite `diet_comp_clean` with your results. [**Hint:** you'll probably have to use some regex to clean `kcal_source` categories]

```{r}
diet_comp_clean <- diet_comp_clean %>% 
  rename(country = entity) %>%  #changes entity into country
  mutate(kcal_source = str_remove_all(kcal_source, "_[a-z]{3}_[0-9]{4}$")) # removes the end -fao_year from the kcal_source


#alcoholic_beverages_fao_2017
```


**Question 4**

Check how many missing values there are in each column

```{r}
diet_comp_clean %>%
  summarise(count = sum(is.na(diet_comp_clean)))

# stolen from slack
colSums(is.na(diet_comp_clean))
```




**Question 5**

Let's investigate the missing values in column `code` further. First, check which countries are missing a code. Save these as a character vector, and use this vector to check whether you can find their code anywhere in the dataset, i.e. is the code missing for every observation for these countries.


```{r}
missing_code <- diet_comp_clean %>% 
  filter(is.na(code)) %>% 
  distinct(country, keep_all = FALSE) %>% 
  pull(country)
  



diet_comp_clean %>% 
  select(contains("missing_code"))

diet_comp_clean %>% 
  str_detect("missing_code")  ## the best option - returns [1] FALSE FALSE FALSE FALSE FALSE





str_c(missing_code, sep = "", collapse = NULL) # trying to change vector into 1 string to use

missing_code_single %>%
  mutate(code = str_c(missing_code, sep = " "))  # trying to change vector into 1 string to use


 str_extract(diet_comp_clean, missing_code) 

 
 
diet_comp_clean %>% 
  filter(str_detect(country, missing_code))
  
```


**Question 6**

Ok, we have no available country codes for Cabo Verde and the US in this dataset. Is there anything in the data source about what these should be? No... Ok, better find something online then. Google tells us there's something called ISO Alpha-3 codes which look pretty promising. Wait, what's that in your data folder? Read it in! Then find the missing codes!

```{r}
country_codes <- read_csv("data/country_codes.csv")
clean_country_codes <- clean_names(country_codes)


# changes names in clean country codes - now Cabo Verde and United States of America

clean_country_codes_cvus <- clean_country_codes %>% 
  mutate(country = case_when(country %in% "Cape Verde" ~ "Cabo Verde",
                             country %in% "United States" ~ "United States of America",
                             TRUE ~ country))
                             
                            
# joins diet info with country codes

diet_comp_with_codes <- diet_comp_clean %>% 
  left_join(clean_country_codes_cvus, by = "country")
  
  



```


**Question 7**

Using a suitable recoding function, fill in the lost (but now found) country codes. Overwrite `diet_comp_clean` again. Finally, check that there are now no missing values in the code column.

```{r}
# replace na observations in the monthly_charges column, with the median of that column
# comms_data_imputed_median <- comms_data %>% mutate(monthly_charges = coalesce(monthly_charges, median(monthly_charges, na.rm = TRUE)))


# replaces NA in codes with alpha codes
imputed_diet <- diet_comp_with_codes %>% 
  mutate(code = coalesce(code, alpha_3_code))
  
  # checks for NA is code column
imputed_diet %>% 
  summarise(count = sum(is.na(code)))

# overwrites to diet_comp_clean
diet_comp_clean <- diet_comp_with_codes %>% 
  mutate(code = coalesce(code, alpha_3_code))

```



**Question 8**

_Note: Do **NOT** overwrite `diet_comp_clean` with the result of this question._ 

Join the two datasets so only countries with matches in both are retained. Create a new logical column that is `TRUE` if the first two letters of `code` is the same as `alpha_2_code`.

```{r}

# joining the two datasets
alpha_diet_country <- diet_comp_clean %>% 
  semi_join(clean_country_codes, 
             by = "country",
             copy = FALSE,
             keep = FALSE) %>% 
  
## totally stuck on this bit
 select(alpha_diet_country,)
alpha_test <- alpha_diet_country %>% 
str_detect("code", "[A-Z]{2}" == "alpha_3_code", )


library(dplyr)
library(stringr)
df %>%
     mutate(xyz = +(if_any(everything(), 
         ~ str_detect(., regex('aa', ignore_case = TRUE)))))
```


<br>

**Question 9**

That's enough of country codes! Let's look at the actual diets of some countries. Using `diet_comp_clean`, which is hopefully untarnished by the monstrosity that was Question 8, create a new variable called `uk_diet` which only contains data from the UK and with all NAs from `avg_daily_kcals` dropped.


```{r}
# new df with uk data
uk_diet <- diet_comp_clean %>% 
  filter(code == "GBR") %>% 
  mutate("uk_diet" = avg_daily_kcals) %>%  
  drop_na(uk_diet)


# wasn't quite sure of question so this is the UK data joined back in with worldwide data - then all NAs dropped
diet_comp_clean_uk <- diet_comp_clean %>% 
  full_join(uk_diet, by = c("country", 
                            "year", 
                            "code", 
                            "kcal_source", 
                            "alpha_2_code", 
                            "alpha_3_code", 
                            "avg_daily_kcals")) %>% 
  drop_na(avg_daily_kcals)

  
  
```


<br>

**Question 10**

Using `uk_diet`, create a new column that contains the difference in total calories between a year and the year before. Then find the year where there was the biggest positive difference and the biggest negative difference.


```{r}
uk_diet %>% 
  group_by(year) %>% 
  summarise(sum =sum(avg_daily_kcals)) %>% 
  mutate("kcal_year" = sum * 365)
```


**Question 11**

Back to `diet_comp_clean` again. For every year between 1990 and 2000, find which country got the most average daily calories from alcoholic beverages, i.e. you want to end up with one country per year.

<br>

**Question 12**

Now write a function which finds the top calorie source for a user-specified vector of both countries and years. Then use your function to find the top calorie source for the UK and Zimbabwe in 1965, 1975, 1985, 1995 and 2005. Try out your function a few more times for countries/years that you find interesting! Also consider whether there are any limitations of your function.

<br>

**Question 13**

Use your function to find the top calorie source in 1970 for all countries starting with B.

<br>

**Question 14**

If you have made it this far, well done! If you are still itching to do some more data analysis/coding, you can explore the dataset yourself and try to discover something interesting or just practice anything you still feel unsure about!
